{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40274,"status":"ok","timestamp":1718710764277,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"id":"yqmb3yMg_m4_","outputId":"aa973f12-0cea-46d5-aa20-35f3c12fce30"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#gdrive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## Libraries"],"metadata":{"id":"vR6NHwwIUpo3"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60089,"status":"ok","timestamp":1718710824356,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"id":"r1q7eMLk_qC2","outputId":"16bda5bc-d26c-41ba-a814-e6ee75c32523","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Collecting accelerate\n","  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch])\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n","Successfully installed accelerate-0.31.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"]}],"source":["!pip install transformers[torch] accelerate -U"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5510,"status":"ok","timestamp":1718710829850,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"id":"X-y-7eyD_4K5","outputId":"4ba5df12-6ac4-4d60-f923-80bc27ccd869","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install torch torchvision transformers"]},{"cell_type":"code","source":["!pip install rouge_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8pJ_TOyc7Eq","executionInfo":{"status":"ok","timestamp":1718710836224,"user_tz":-330,"elapsed":6404,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"a9f73661-b9a1-4143-c063-de71a885ffdf","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.4)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=8b526c1291952dd5c3a3ea5129e94831c7ecc1797bd8b87832d2aa0479ea7325\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G79HV59c_6Vw"},"outputs":[],"source":["\n","#imports\n","import os\n","import json\n","import torch\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, BertTokenizer, BertModel, T5Config\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","import torch\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yzAfVfBi_8Hl"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","from collections import Counter\n","from transformers import (BertTokenizer, BertModel, T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq, get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup)\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mTTrNHyr_9TA"},"outputs":[],"source":["# from sklearn.metrics import accuracy_score, f1_score\n","# import numpy as np\n","# from datasets import load_metric\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Tj2LrpvBz6y"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1718710846116,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"id":"c2RmD3lsrxCd","outputId":"44e2fc89-2c5c-4298-d721-141c945b33d6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":9}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":958,"status":"ok","timestamp":1718710847067,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"id":"7FteqgdjsTNE","outputId":"ea1fcfda-185a-4399-f2af-1c1da549f2b8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["tf.test.gpu_device_name()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ydX4WaR8wK7"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1718710847068,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"id":"uZHwPWyQ84Y0","outputId":"a62c525b-eea5-429d-c38d-be67bd24dd4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["print(f\"Using device: {device}\")"]},{"cell_type":"markdown","source":["## Simple"],"metadata":{"id":"SUy1Qh0JNWg-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3oRZ-J4LQR_"},"outputs":[],"source":["#lists\n","json_data=[]\n","prompts=[]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C44k1LA4XQDb"},"outputs":[],"source":["# load json-only\n","json_only= '/content/drive/My Drive/Implementation/Final Thesis/json_only.jsonl'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfQyWdMom99r"},"outputs":[],"source":["with open(json_only, 'r', encoding='utf-8') as f:\n","  for line in f:\n","    json_data.append(json.loads(line))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0VwBgFlCnN5m"},"outputs":[],"source":["# load prompt only\n","prompt_only= '/content/drive/My Drive/Implementation/Final Thesis/prompt_only.txt'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A14ca-_0nR1K"},"outputs":[],"source":["with open(prompt_only, 'r', encoding='utf-8') as f:\n","  prompts =[line.strip() for line in f]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1718005271270,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"id":"38KiTIi2TN3-","outputId":"93235203-2213-4181-ad4f-74ea230077ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of prompts: 28085\n","Number of JSON entries: 28085\n"]}],"source":["print(f\"Number of prompts: {len(prompts)}\")\n","print(f\"Number of JSON entries: {len(json_data)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1718005283452,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"id":"2PJUEwLvDla4","outputId":"90aa46de-a4b0-4a5c-eb71-1e159daf64cc","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Example JSON entry:\n","{\n","  \"variant_properties\": {\n","    \"color\": \"rgba(255, 255, 255, 1.0)\",\n","    \"strokes\": [\n","      \"rgba(126, 86, 216, 1.0)\"\n","    ],\n","    \"strokeWeight\": 1.0,\n","    \"text\": \"Button CTA\",\n","    \"textColor\": \"rgba(255, 255, 255, 1.0)\",\n","    \"borderRadius\": 10.0,\n","    \"fontFamily\": \"Inter\",\n","    \"fontWeight\": 500,\n","    \"fontSize\": 14.0,\n","    \"effects\": [\n","      {\n","        \"type\": \"DROP_SHADOW\",\n","        \"color\": \"rgba(16, 24, 40, 0.05000000074505806)\"\n","      }\n","    ],\n","    \"padding\": 0,\n","    \"width\": 77.0,\n","    \"height\": 20.0,\n","    \"x\": -4619.0,\n","    \"y\": -2135.0,\n","    \"style\": \"Professional\",\n","    \"component_name\": \"Button\",\n","    \"subtype\": \"Default\",\n","    \"variant_details\": {\n","      \"State\": [\n","        \"Default\"\n","      ],\n","      \"Size\": [\n","        \"Small\"\n","      ]\n","    }\n","  }\n","}\n"]}],"source":["# Example of a JSON entry\n","print(\"Example JSON entry:\")\n","print(json.dumps(json_data[0], indent=2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3mAj-DZT6D90"},"outputs":[],"source":["class UIDataset(Dataset):\n","   \"\"\" class for loading paired dataset \"\"\"\n","\n","  def __init__(self, prompts, json_data):\n","    \"\"\"method to initialize the class\n","    Parameters:\n","    prompts (list): list of prompts\n","    json_data (list): list of JSON data\n","    \"\"\"\n","    #initialise prompts\n","    self.prompts= prompts\n","    #initialise json data\n","    self.json_data= json_data\n","    #loading bert tokenizer\n","    self.bert_tokenizer= BertTokenizer.from_pretrained('bert-base-uncased')\n","    self.t5_tokenizer= T5Tokenizer.from_pretrained('t5-small')\n","    #bert model\n","    self.bert_model= BertModel.from_pretrained('bert-base-uncased').to(device)\n","\n","  def __len__(self):\n","    \"\"\" method to return the length of the dataset \"\"\"\n","    return len(self.prompts)\n","\n","  def __getitem__(self, idx):\n","    \"\"\" method to return the item at the given index\n","    Parameters:\n","    idx (int): index of the item\n","    Returns:\n","    dict: dictionary containing the input_ids, attention_mask, labels, and bert_embeddings\n","    \"\"\"\n","    #indices of promtp and json\n","    prompt= self.prompts[idx]\n","    json_entry =json.dumps(self.json_data[idx])\n","\n","    #bert used to convert prompts to tokens\n","    inputs= self.bert_tokenizer(prompt, return_tensors='pt', padding='max_length', truncation=True, max_length=512).to(device)\n","    #bert embeddings generated without gradient\n","    with torch.no_grad():\n","        outputs =self.bert_model(**inputs)\n","    #average last hidden states from bert to get a single embedding vector for the prompt\n","    bert_embeddings= outputs.last_hidden_state.mean(dim=1).squeeze()\n","\n","    # check for NaN in embeddings\n","    if torch.isnan(bert_embeddings).any():\n","      print(f\"NaN detected in BERT embeddings at index {idx}\")\n","\n","    #t5 tokenizer to conver prompt to tokens\n","    t5_inputs= self.t5_tokenizer(prompt, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n","    #t5 tokenizer to convert json to tokens\n","    targets =self.t5_tokenizer(json_entry, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n","\n","    return {\n","      'input_ids':t5_inputs['input_ids'].squeeze(),\n","      'attention_mask':t5_inputs['attention_mask'].squeeze(),\n","      'labels': targets['input_ids'].squeeze(),\n","      'bert_embeddings':bert_embeddings\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":477,"referenced_widgets":["6c16dfba37ab4a07837e6761671b162c","bbec4268cf774f6bb205015b3c8cb87c","0e8519583e8c4583ac5bc4ed7475b8cd","083cd1a8da9b4093ae23b0d233d08dc6","3d94a12c468a47fbbf05e3a566420b66","110de3f44b174cb786e1f5fb7f631839","36fbe96f8c804b39a73f32ba7722b9de","5dae370e508548bb927aaed7a5e7fad8","6b0f4e2283a841acab1d07f3584a3211","0e918e02ff4d4830a4a4c5f404e50112","dc6ac7c852c14b708e601504697fbbd4","65c57afb6f5043a2add3c6af7af07a95","d4c0a5ed3bc244339e15c827a96ffefe","88b9a70da82e4ad9a7ce9d1035fd92ad","2c92842997094c70893db8b967871549","8867c12d6b034897b16f91402244f333","542b9f4fbe3849dc92795a4574864132","df1882ccd80544b5bec952e250451ea5","779e63e71cc04803969593ca3ffeaf4c","8bcad1951727455ea68ad23d419128dc","b446c945cf764f2cac1b2f8b6d61521e","d9fcd38a2af44b28a3d8afd67f5a140a","245f2e295b1a4d7eba2742bbdc4db771","4b8475befd5342a2a2cae98bcb5f3eea","c7b1bb35879a4361b102967b4631eee4","c9c7970114b14a0fb657cec8f9585085","7b5067e099194fc7a3dc64d5f027f485","17a5a49d385f43e0b205a247b4f731c0","4a0de5820ee64301b950044977c3bf95","53079e505fa943c88c0ed6ada4c43e8d","eb9ec75c2ce74629818463a3e0b76369","b742819c36c349e8a356afd8279bed8f","51e20ec44b6740289ce77c96bf0ec927","b1bbc741e80a4e4a958beee0c25fd2f3","ab581ce3bfb44fd6a2ab268f0e0ef0c7","5c1d2452c08c4573803db56d4e491002","073fb82d5d014e0cb75386179c70e3c4","15823ae2f74843f096a0afa30927617e","0b08576f8c0b4f41a6765f3ce018c4a5","8aafc6d2583a42db9a29dd9bbeb44c53","ae70960250b44f59ad373d1a986f2c76","c24bbd022b174601872a0484c0fcb928","a98cd2ffff1f4250bcdf29211fd7dee2","f83178a6d7924071b0985052d513c789","b0a7ff38fa0c4ce0a5f40e7eae3b88e1","7dca6a89e1284ecc88b79df35a66160b","fffe9e61321c412f9c7b99de06076b98","5b42baf65f7c44a189e1ceee8563819b","72c41f0bd39447fcb398737b149285fc","7fe0b66e42df4e08ac315a2c5bff573e","41022d6c673e4ca3bf69dfb407d59b78","b73bb014c99c49b498515896ecc5ba17","81d2e72ebbdf4e06b8c2b3c6b591e1ac","35a975c242b0493c96dd9a0a240986a2","9d56eb7db23f43688801d5a7ec9fe4c2","016f0264dca1455bb0bb147a1026fbc6","02d5551b6946412d854316917a9aa289","c6cdd32e69d04b15932d77f880cea07d","fe5a19d6ea694e249c053e8e8952c636","8e733cf3513542eea44b856a7c00dccc","2b6c70db7c614597af4d28edf2d1fb13","1bf2c0a720f04b6aa85442bc28676ce3","e0a048b7a9754d9cb9ed333050a601dc","7aad9107ad2646b5a6803d672e01aaad","27ce6c258c1d485d896a135fc7df8275","009b8f4e042a4a1592ba6a0c7076def8","d47348a8e5b845d698132111767194f4","fa0f9e83f7ff4360b9d3f15261f7e0ea","53f6d196bd42443e9f56352065313809","2ae616b53dd241d8bfc46ccb5208a4b1","3d9bbdd495194ba18b4417be8ac86d22","21c8c6a8632b4ac38168609c3ba20863","7b157bf3745b4055a674350ea4b62384","f24594b8df964a00b8108097f950b19c","edca598b10e74a30aa753c3f2d6e3848","b065ee80eef144dfbee36ecf6ba56c94","40a104105bc14d219193df623fc90465","6f22d02369534694b4f276c2b6fbcabe","a8800915bf7847c1b9bd55430b1121a5","23b43fbe94dd4ddbb23ce7f2aedfb98f","7c5e4bb5b9a1436d8153b492713e0b52","89f97101efb04978a58da5e291933f6b","a1955ab2511241ce9a7f21f24db54be8","e6911b05e304460dbe9d0879051b8247","31293e1ed404428c9f5c4a936c7e38ec","97a2eb9f0c0d4393b3a4d56d8000570e","ca2f3fc8b98347e4b3b8d5ac8d2b5a70","f34e1bd2d2d64b4fbad97cf98bf733fb"]},"executionInfo":{"elapsed":10786,"status":"ok","timestamp":1717958072654,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"id":"xsOEO1hT7H8A","outputId":"09615a6a-8a17-43c9-8d96-3c396ccf3192","collapsed":true},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c16dfba37ab4a07837e6761671b162c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65c57afb6f5043a2add3c6af7af07a95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"245f2e295b1a4d7eba2742bbdc4db771"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1bbc741e80a4e4a958beee0c25fd2f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0a7ff38fa0c4ce0a5f40e7eae3b88e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"016f0264dca1455bb0bb147a1026fbc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d47348a8e5b845d698132111767194f4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f22d02369534694b4f276c2b6fbcabe"}},"metadata":{}}],"source":["dataset= UIDataset(prompts, json_data)\n","#split the dataset\n","total_size= len(dataset)\n","train_size= int(0.8 * total_size)\n","val_size= int(0.1 * total_size)\n","test_size= total_size - train_size - val_size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VLZGS1BAZELf"},"outputs":[],"source":["train_dataset, val_dataset, test_dataset= random_split(dataset, [train_size, val_size, test_size])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"26xtzSBtZFLk"},"outputs":[],"source":["#dataloaders\n","train_loader= DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_loader= DataLoader(val_dataset, batch_size=4)\n","test_loader= DataLoader(test_dataset, batch_size=4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dobQsPbxZRC7"},"outputs":[],"source":["#tokenizers and models bert\n","bert_tokenizer =BertTokenizer.from_pretrained('bert-base-uncased')\n","bert_model= BertModel.from_pretrained('bert-base-uncased')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["39ed39a45385449fa405148cac55a0b3","f38285c1407b4e0ea6a2b181626e4e1c","8ab0949b42134f258d9c8fba04dd2da4","18ffa2ff4c7f45b5a877bfdf1e4d9d94","3a426cbe30d94adab6b9a01cc7b2b932","5b9323aa944e4ebd808cfd4b629f4d4a","1983a7898198474fb027ac52d9b877ba","550ef2a0008349919dca50d3f3726338","1e1fe2626f124ed0972686477c34fdff","b9dc5bdd1aec46d2b15af1714ca15e40","b756f98d602d4957a5818179973f8a32","aed87e36495940e5acc866fba5cdb066","ef71b336ccfe4959a6261b0da0017b28","f14786f0c84948de9d3054efb0928f50","db045e0d09f146618aa9ac27455adb35","8199be36cb3e43e1b9f92e8e4a67890a","8f864738a7884333828934549ef04f55","bde57b79362b45999bd1e29e857fb689","ebf7a9b6506e4ff38cb47e65c45ade26","73f5513418734247855aea71596127af","a1b6eac649574cdfbedfbb41a6c65601","6316c4be7844463ca7c80788f1a09a96","a4010ea7775740f69f8e4b54b64361c8","f627a42861654d0e84c312ac259fa75d","ca5b1325394f4d69b0c587b683a32c3b","c944ff2044904d9b8fd2066bce303dab","a39ca21b1b564204bfa1d20d34a4783e","0d31b9e61e754f86852c06d2e217e694","8c0298cc48b94c58bf6d1197e825f620","883aa355b39f43c1878cc20be46c905e","4daf686d65b3463eb4edc708080514a3","fc0f22c815664a64b84ae607179972dd","aee2d2f8b7224b1da453880f30ec30f8"]},"executionInfo":{"elapsed":2671,"status":"ok","timestamp":1717958076335,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"id":"7MekwSMFabP0","outputId":"d3dd0093-437a-4bbf-d00a-69ca8b013c94","collapsed":true},"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39ed39a45385449fa405148cac55a0b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aed87e36495940e5acc866fba5cdb066"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4010ea7775740f69f8e4b54b64361c8"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 512)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 8)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-5): 5 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 8)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-5): 5 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":29}],"source":["#tokenizers and models t5\n","t5_tokenizer= T5Tokenizer.from_pretrained('t5-small')\n","t5_model =T5ForConditionalGeneration.from_pretrained('t5-small')\n","\n","#move to device\n","device= 'cuda' if torch.cuda.is_available() else 'cpu'\n","bert_model.to(device)\n","t5_model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1717958076335,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"id":"FfeLG2OlZVkn","outputId":"70750411-82fc-4fa8-d547-83cc22708648"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["# Training arguments\n","training_args= TrainingArguments(\n","  output_dir='/content/drive/My Drive/Implementation/Final Thesis/FYP/JSON generation/T5 CROSS SIMPLE',\n","  num_train_epochs=3,\n","  #training batch size\n","  per_device_train_batch_size=4,\n","  #evaluation batch size\n","  per_device_eval_batch_size=4,\n","  save_steps=500,\n","  save_total_limit=2,\n","  logging_steps=10,\n","  eval_steps=500,\n","  evaluation_strategy=\"steps\",\n","  prediction_loss_only=True,\n","  load_best_model_at_end=True,\n","  fp16=torch.cuda.is_available(),\n","  #not push to HF\n","  push_to_hub=False\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Py5hJY6_ZW51"},"outputs":[],"source":["#DATALOADER for seq2seq\n","data_collator= DataCollatorForSeq2Seq(tokenizer=t5_tokenizer, model=t5_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rhy8vRmCahyZ"},"outputs":[],"source":["class T5WithCrossAttention(T5ForConditionalGeneration):\n","  \"\"\" class for T5 model with cross attention \"\"\"\n","  def __init__(self, config):\n","    \"\"\" method to initialize the class\n","    Parameters:\n","    config (dict): configuration of the model\n","    \"\"\"\n","    super().__init__(config)\n","    #initialise multi head attention layer for cross attention\n","    self.cross_attention =torch.nn.MultiheadAttention(embed_dim=config.d_model, num_heads=8)\n","    #initialise linear layer to put out bert embeddings to t5 hidden state dimension\n","    self.bert_proj= torch.nn.Linear(bert_model.config.hidden_size, config.d_model)\n","\n","  def forward(self, input_ids, attention_mask=None, decoder_input_ids=None, labels=None, bert_embeddings=None):\n","    \"\"\" method to forward the input\n","    Parameters:\n","    input_ids (tensor): input tokens\n","    attention_mask (tensor): attention mask\n","    decoder_input_ids (tensor): decoder input tokens\n","    labels (tensor): labels\n","    bert_embeddings (tensor): bert embeddings\n","    Returns:\n","    tuple: loss and logits\n","    \"\"\"\n","    #pass inputs through t5 encoder\n","    outputs= self.encoder(input_ids=input_ids,attention_mask=attention_mask,)\n","\n","    hidden_states= outputs[0]\n","\n","    #bert embeddings to match the T5 hidden state dimension\n","    bert_embeddings= self.bert_proj(bert_embeddings).unsqueeze(1).expand(-1, hidden_states.size(1), -1)\n","\n","    #putting cross-attention between T5 embeddings and BERT embeddings\n","    hidden_states, _= self.cross_attention(hidden_states, bert_embeddings, bert_embeddings)\n","\n","    #pass inputs through t5 decoder\n","    decoder_outputs= self.decoder(input_ids=decoder_input_ids,encoder_hidden_states=hidden_states,encoder_attention_mask=attention_mask,)\n","\n","    sequence_output = decoder_outputs[0]\n","    lm_logits = self.lm_head(sequence_output)\n","\n","    loss = None\n","    if labels is not None:\n","      loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100)\n","      #flatten logits and labels for loss computation\n","      lm_logits = lm_logits.view(-1, lm_logits.size(-1))\n","      #labels\n","      labels = labels.view(-1)\n","      if lm_logits.size(0)== labels.size(0):\n","        loss = loss_fct(lm_logits, labels)\n","      else:\n","        print(f\"Shape mismatch between logits and labels: {lm_logits.size()} vs {labels.size()}\")\n","\n","    return loss, lm_logits\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tiRY2M50aBYI"},"outputs":[],"source":["# t5_model = T5WithCrossAttention.from_pretrained('t5-small').to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lzhCCfKpZcpf"},"outputs":[],"source":["#Trainer instance\n","trainer = Trainer(\n","  model=t5_model,\n","  args=training_args,\n","  train_dataset=train_dataset,\n","  eval_dataset=val_dataset,\n","  data_collator=data_collator\n",")"]},{"cell_type":"code","source":["#path\n","checkpoint_path= \"/content/drive/My Drive/Implementation/Final Thesis/FYP/UpdatedResults/checkpoint-16500\""],"metadata":{"id":"Hujcfmm-p685"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LOAD\n","loaded_model= T5ForConditionalGeneration.from_pretrained(checkpoint_path).to(device)"],"metadata":{"id":"zDfHoBaUqEid"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["original_model_path= \"t5-small\""],"metadata":{"id":"LWyN3cLaq5EZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LOAD TOKENIZER\n","loaded_tokenizer= T5Tokenizer.from_pretrained(original_model_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bYcvMnMtqGBT","executionInfo":{"status":"ok","timestamp":1717964724677,"user_tz":-330,"elapsed":3,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"9022c2c3-f925-4e5a-a653-6e74eae9e5b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"markdown","source":["### Inference"],"metadata":{"id":"xXqcgGpz_rCp"}},{"cell_type":"code","source":["def generate_json_from_description(description, model, tokenizer, max_length=512):\n","  \"\"\" method to generate JSON from description\n","  Parameters:\n","  description (str): description\n","  model (T5ForConditionalGeneration): model\n","  tokenizer (T5Tokenizer): tokenizer\n","  max_length (int): maximum length of the generated JSON\n","  Returns:\n","  str: generated JSON\n","  \"\"\"\n","  #tokenize input description\n","  input_ids= tokenizer(description, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_length).input_ids.to(device)\n","  #generate JSON output\n","  generated_ids= model.generate(input_ids, max_length=max_length, num_beams=5, early_stopping=True)\n","  #decode generated tokens to JSON string\n","  generated_json =tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","  return generated_json"],"metadata":{"id":"X8_7O_oMrUyq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["description=\"Create a professional label with a drop shadow effect\""],"metadata":{"id":"DbuqnbLKrXy9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generated_json= generate_json_from_description(description, loaded_model, loaded_tokenizer)\n"],"metadata":{"id":"oPzMXdt5rfYG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(generated_json)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p-Uy164grglF","executionInfo":{"status":"ok","timestamp":1717965049657,"user_tz":-330,"elapsed":14,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"6c795978-9286-4190-b240-b5210c6c42fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\"variant_properties\": \"color\": \"rgba(255, 255, 255, 1.0)\", \"strokes\": [], \"strokeWeight\": 1.0, \"text\": \"Label\", \"textColor\": \"rgba(255, 255, 255, 1.0)\", \"borderRadius\": 8.0, \"fontFamily\": \"Roboto\", \"fontWeight\": 500, \"fontSize\": 14.0, \"effects\": [\"type\": \"DROP_SHADOW\", \"color\": \"rgba(0, 0, 0, 0.30000001192092896)\", \"type\": \"DROP_SHADOW\", \"color\": \"rgba(0, 0, 0, 0.15000000596046448)\"], \"padding\": 0, \"width\": 35.0, \"height\": 20.0, \"x\": -5349.0, \"y\": -4313.0, \"style\": \"Professional\", \"component_name\": \"label\", \"subtype\": \"Light\", \"variant_details\": \"Style\": [\"outlined\"], \"State\": [\"dragged\"]\n"]}]},{"cell_type":"code","source":["# save_path= \"/content/drive/My Drive/Implementation/Final Thesis/FYP/UpdatedResults/unfinished_model\""],"metadata":{"id":"HlMlO5txs_F8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# if not os.path.exists(save_path):\n","#   os.makedirs(save_path)"],"metadata":{"id":"lpMxQu-hs_44"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loaded_model.save_pretrained(save_path)\n","# loaded_tokenizer.save_pretrained(save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QUwk_NVCtBiB","executionInfo":{"status":"ok","timestamp":1717965179073,"user_tz":-330,"elapsed":1985,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"c50bc02f-6d76-4705-d86e-448d8fc55a33"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/drive/My Drive/Implementation/Final Thesis/FYP/UpdatedResults/unfinished_model/tokenizer_config.json',\n"," '/content/drive/My Drive/Implementation/Final Thesis/FYP/UpdatedResults/unfinished_model/special_tokens_map.json',\n"," '/content/drive/My Drive/Implementation/Final Thesis/FYP/UpdatedResults/unfinished_model/spiece.model',\n"," '/content/drive/My Drive/Implementation/Final Thesis/FYP/UpdatedResults/unfinished_model/added_tokens.json')"]},"metadata":{},"execution_count":79}]},{"cell_type":"markdown","source":[],"metadata":{"id":"b6_yQ-amYar-"}},{"cell_type":"markdown","source":["## Training again1 with pairs"],"metadata":{"id":"TT-gDJlEJrA_"}},{"cell_type":"code","source":["# Load the paired dataset\n","pairs_file_1= '/content/drive/My Drive/Implementation/Final Thesis/FYP/Data/t5_json_description_pairs.jsonl'\n"],"metadata":{"id":"roKiHjXW7g8m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","data_pairs_1= []\n"],"metadata":{"id":"UnWHN8Fz9OUS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(pairs_file_1, 'r', encoding='utf-8') as f:\n","  for line in f:\n","    data_pairs_1.append(json.loads(line))\n"],"metadata":{"id":"dtFiWaT19POp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["json_data_1 =[pair['input'] for pair in data_pairs_1]\n"],"metadata":{"id":"rFztnXGK_BaH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompts_1= [pair['output'] for pair in data_pairs_1]\n"],"metadata":{"id":"2V-7_W-B_Bo2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Number of pairs: {len(data_pairs_1)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jk3TR3W_CxO","executionInfo":{"status":"ok","timestamp":1718569447670,"user_tz":-330,"elapsed":10,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"f34b2224-58de-4fab-f966-f7618dfef7cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of pairs: 28300\n"]}]},{"cell_type":"code","source":["print(f\"Number of jsno: {len(json_data_1)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abwbVvT3_EG2","executionInfo":{"status":"ok","timestamp":1718569447670,"user_tz":-330,"elapsed":10,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"559b4e04-75b8-4da6-fa48-fe1edd248f12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of jsno: 28300\n"]}]},{"cell_type":"code","source":["print(f\"Number of description: {len(prompts_1)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QMhzuByl_KFg","executionInfo":{"status":"ok","timestamp":1718569447670,"user_tz":-330,"elapsed":8,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"89b42e74-3c69-49e2-9b7f-28c190f6a562"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of description: 28300\n"]}]},{"cell_type":"code","source":["for i in range(2):\n","  print(f\"JSON: {json_data_1[i]}\")\n","  print(f\"Description: {prompts_1[i]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WRY2kgowBmU8","executionInfo":{"status":"ok","timestamp":1718569447671,"user_tz":-330,"elapsed":8,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"a3f47a8e-a348-4bb4-aeb1-52278d0cdd24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["JSON: {\"variant_properties\": {\"color\": \"rgba(255, 255, 255, 1.0)\", \"strokes\": [\"rgba(126, 86, 216, 1.0)\"], \"strokeWeight\": 1.0, \"text\": \"Button CTA\", \"textColor\": \"rgba(255, 255, 255, 1.0)\", \"borderRadius\": 10.0, \"fontFamily\": \"Inter\", \"fontWeight\": 500, \"fontSize\": 14.0, \"effects\": [{\"type\": \"DROP_SHADOW\", \"color\": \"rgba(16, 24, 40, 0.05000000074505806)\"}], \"padding\": 0, \"width\": 77.0, \"height\": 20.0, \"x\": -4619.0, \"y\": -2135.0, \"hasIcon\": false, \"style\": \"Professional\", \"component_name\": \"Button\", \"subtype\": \"Default\", \"variant_details\": {\"State\": [\"Default\"], \"Size\": [\"Small\"]}}}\n","Description: A Button with border radius 10.0.\n","JSON: {\"variant_properties\": {\"color\": \"rgba(255, 255, 255, 1.0)\", \"strokes\": [\"rgba(126, 86, 216, 1.0)\"], \"strokeWeight\": 1.0, \"text\": \"Button CTA\", \"textColor\": \"rgba(255, 255, 255, 1.0)\", \"borderRadius\": 10.0, \"fontFamily\": \"Inter\", \"fontWeight\": 500, \"fontSize\": 14.0, \"effects\": [{\"type\": \"DROP_SHADOW\", \"color\": \"rgba(16, 24, 40, 0.05000000074505806)\"}], \"padding\": 0, \"width\": 77.0, \"height\": 20.0, \"x\": -4619.0, \"y\": -2135.0, \"hasIcon\": false, \"style\": \"Professional\", \"component_name\": \"Button\", \"subtype\": \"Default\", \"variant_details\": {\"State\": [\"Default\"], \"Size\": [\"Small\"]}}}\n","Description: Generate a Professional Button with State of Default, Size of Small.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oME772GuJ-pS"},"outputs":[],"source":["class UIDataset(Dataset):\n","  \"\"\" class for loading paired dataset \"\"\"\n","\n","  def __init__(self, prompts, json_data):\n","    \"\"\"method to initialize the class\n","    Parameters:\n","    prompts (list): list of prompts\n","    json_data (list): list of JSON data\n","    \"\"\"\n","    #initialise prompts\n","    self.prompts= prompts\n","    #initialise json data\n","    self.json_data=json_data\n","    #loading bert tokenizer\n","    self.bert_tokenizer= BertTokenizer.from_pretrained('bert-base-uncased')\n","    self.t5_tokenizer =T5Tokenizer.from_pretrained('t5-small')\n","    #bert model\n","    self.bert_model= BertModel.from_pretrained('bert-base-uncased').to(device)\n","\n","  def __len__(self):\n","    \"\"\" method to return the length of the dataset \"\"\"\n","    return len(self.prompts)\n","\n","  def __getitem__(self, idx):\n","    \"\"\" method to return the item at the given index\n","    Parameters:\n","    idx (int): index of the item\n","    Returns:\n","    dict: dictionary containing the input_ids, attention_mask, labels, and bert_embeddings\n","    \"\"\"\n","    #indices of promtp and json\n","    prompt= self.prompts[idx]\n","    json_entry =json.dumps(self.json_data[idx])\n","\n","    #bert used to convert prompts to tokens\n","    inputs= self.bert_tokenizer(prompt, return_tensors='pt', padding='max_length', truncation=True, max_length=512).to(device)\n","    #bert embeddings generated without gradient\n","    with torch.no_grad():\n","      outputs = self.bert_model(**inputs)\n","    #average last hidden states from bert to get a single embedding vector for the prompt\n","    bert_embeddings= outputs.last_hidden_state.mean(dim=1).squeeze()\n","\n","    # check for NaN in embeddings\n","    if torch.isnan(bert_embeddings).any():\n","      print(f\"NaN detected in BERT embeddings at index {idx}\")\n","\n","    #t5 tokenizer to conver prompt to tokens\n","    t5_inputs= self.t5_tokenizer(prompt, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n","    #t5 tokenizer to convert json to tokens\n","    targets = self.t5_tokenizer(json_entry, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n","\n","    return {\n","      'input_ids':t5_inputs['input_ids'].squeeze(),\n","      'attention_mask':t5_inputs['attention_mask'].squeeze(),\n","      'labels': targets['input_ids'].squeeze(),\n","      'bert_embeddings': bert_embeddings\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4709,"status":"ok","timestamp":1718569452375,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"outputId":"9e8d362a-2496-42b9-f39a-11db516e7e4b","id":"MMaD-6pzJ-pT"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# Split the dataset\n","dataset= UIDataset(prompts_1, json_data_1)\n","total_size =len(dataset)\n","train_size= int(0.8 * total_size)\n","val_size =int(0.1 * total_size)\n","test_size= total_size - train_size - val_size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8p-WuFURJ-pT"},"outputs":[],"source":["train_dataset, val_dataset, test_dataset= random_split(dataset, [train_size, val_size, test_size])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"erane6qTJ-pT"},"outputs":[],"source":["#dataloaders\n","train_loader= DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_loader= DataLoader(val_dataset, batch_size=4)\n","test_loader= DataLoader(test_dataset, batch_size=4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zm_4OTl3J-pU"},"outputs":[],"source":["#tokenizers and models bert\n","bert_tokenizer =BertTokenizer.from_pretrained('bert-base-uncased')\n","bert_model =BertModel.from_pretrained('bert-base-uncased')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2130,"status":"ok","timestamp":1718569501122,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"outputId":"3e228234-c45c-447b-c16e-89af77a004fc","id":"Ax1XEXsEJ-pU","collapsed":true},"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 512)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 8)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-5): 5 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 8)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-5): 5 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":35}],"source":["#tokenizers and models t5\n","t5_tokenizer= T5Tokenizer.from_pretrained('t5-small')\n","t5_model= T5ForConditionalGeneration.from_pretrained('t5-small')\n","\n","#move to device\n","device= 'cuda' if torch.cuda.is_available() else 'cpu'\n","bert_model.to(device)\n","t5_model.to(device)"]},{"cell_type":"code","source":["epochs=10"],"metadata":{"id":"rhdA2gsrjNYs"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1718569452375,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"outputId":"9cbbc48d-1c3c-4af7-e687-5b83cf91a8cc","id":"xEdvsbjdJ-pU"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["# Training arguments\n","training_args= TrainingArguments(\n","  output_dir='/content/drive/My Drive/Implementation/Final Thesis/FYP/JSON generation/T5 CROSS SIMPLE',\n","  num_train_epochs=epochs,\n","  #training batch size\n","  per_device_train_batch_size=16,\n","  #evaluation batch size\n","  per_device_eval_batch_size=16,\n","  save_steps=500,\n","  save_total_limit=2,\n","  logging_steps=10,\n","  eval_steps=500,\n","  evaluation_strategy=\"steps\",\n","  #loss calculated during validation\n","  prediction_loss_only=True,\n","  load_best_model_at_end=True,\n","  fp16=torch.cuda.is_available(),\n","  #not push to HF\n","  push_to_hub=False\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hco-22HRJ-pV"},"outputs":[],"source":["data_collator= DataCollatorForSeq2Seq(tokenizer=t5_tokenizer, model=t5_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_09Hk4pcJ-pV"},"outputs":[],"source":["class T5WithCrossAttention(T5ForConditionalGeneration):\n","  \"\"\" class for T5 model with cross attention \"\"\"\n","  def __init__(self, config):\n","    \"\"\" method to initialize the class\n","    Parameters:\n","    config (dict): configuration of the model\n","    \"\"\"\n","    super().__init__(config)\n","    #initialise multi head attention layer for cross attention\n","    self.cross_attention= torch.nn.MultiheadAttention(embed_dim=config.d_model, num_heads=8)\n","    #initialise linear layer to put out bert embeddings to t5 hidden state dimension\n","    self.bert_proj = torch.nn.Linear(bert_model.config.hidden_size, config.d_model)\n","\n","  def forward(self, input_ids, attention_mask=None, decoder_input_ids=None, labels=None, bert_embeddings=None):\n","    \"\"\" method to forward the input\n","    Parameters:\n","    input_ids (tensor): input tokens\n","    attention_mask (tensor): attention mask\n","    decoder_input_ids (tensor): decoder input tokens\n","    labels (tensor): labels\n","    bert_embeddings (tensor): bert embeddings\n","    Returns:\n","    tuple: loss and logits\n","    \"\"\"\n","    #pass inputs through t5 encoder\n","    outputs= self.encoder(input_ids=input_ids,attention_mask=attention_mask,)\n","    hidden_states= outputs[0]\n","\n","    #bert embeddings to match the T5 hidden state dimension\n","    bert_embeddings= self.bert_proj(bert_embeddings).unsqueeze(1).expand(-1, hidden_states.size(1), -1)\n","\n","    #putting cross-attention between T5 embeddings and BERT embeddings\n","    hidden_states, _= self.cross_attention(hidden_states, bert_embeddings, bert_embeddings)\n","\n","    #pass inputs through t5 decoder\n","    decoder_outputs= self.decoder(input_ids=decoder_input_ids,encoder_hidden_states=hidden_states,encoder_attention_mask=attention_mask,)\n","\n","    sequence_output= decoder_outputs[0]\n","    lm_logits= self.lm_head(sequence_output)\n","\n","    loss = None\n","    if labels is not None:\n","      loss_fct= torch.nn.CrossEntropyLoss(ignore_index=-100)\n","      #flatten logits and labels for loss computation\n","      lm_logits= lm_logits.view(-1, lm_logits.size(-1))\n","      #labels\n","      labels =labels.view(-1)\n","      if lm_logits.size(0)== labels.size(0):\n","        loss = loss_fct(lm_logits, labels)\n","      else:\n","        print(f\"Shape mismatch between logits and labels: {lm_logits.size()} vs {labels.size()}\")\n","\n","    return loss, lm_logits\n"]},{"cell_type":"code","source":["#Trainer instance\n","trainer = Trainer(\n","  model=t5_model,\n","  args=training_args,\n","  train_dataset=train_dataset,\n","  eval_dataset=val_dataset,\n","  data_collator=data_collator\n",")"],"metadata":{"id":"4dpuDWz6Jvbo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":757},"id":"GqHqBG6VLcv8","executionInfo":{"status":"ok","timestamp":1718567504742,"user_tz":-330,"elapsed":5051848,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"1a8020de-5e50-477a-c800-8754596c72df","collapsed":true},"execution_count":null,"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1624' max='7075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1624/7075 24:52 < 1:23:34, 1.09 it/s, Epoch 1.15/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.458900</td>\n","      <td>0.356550</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.353000</td>\n","      <td>0.264545</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.292400</td>\n","      <td>0.226589</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='7075' max='7075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7075/7075 1:49:04, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.458900</td>\n","      <td>0.356550</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.353000</td>\n","      <td>0.264545</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.292400</td>\n","      <td>0.226589</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.248600</td>\n","      <td>0.202615</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.223800</td>\n","      <td>0.186282</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.203500</td>\n","      <td>0.174163</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.209700</td>\n","      <td>0.164607</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.185800</td>\n","      <td>0.157668</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.183800</td>\n","      <td>0.152535</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.199200</td>\n","      <td>0.148562</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.179800</td>\n","      <td>0.145413</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.185500</td>\n","      <td>0.143419</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.175100</td>\n","      <td>0.142022</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.174800</td>\n","      <td>0.141421</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=7075, training_loss=0.2927687621537872, metrics={'train_runtime': 6545.7361, 'train_samples_per_second': 17.294, 'train_steps_per_second': 1.081, 'total_flos': 1.53206919266304e+16, 'train_loss': 0.2927687621537872, 'epoch': 5.0})"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["#path\n","checkpoint_path= \"/content/drive/My Drive/Implementation/Final Thesis/FYP/JSON generation/T5 CROSS SIMPLE.t5_cross_model.pth\""],"metadata":{"id":"85cF1Q8Jne-i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#save for future\n","torch.save(t5_model.state_dict(), checkpoint_path)"],"metadata":{"id":"uQOHvgxgne-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LOAD\n","t5_model= T5ForConditionalGeneration.from_pretrained('t5-small')\n","t5_tokenizer= T5Tokenizer.from_pretrained('t5-small')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3IgPLAllrRZ7","executionInfo":{"status":"ok","timestamp":1718576125666,"user_tz":-330,"elapsed":2464,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"2a56ee00-1840-410f-b5ac-44d15d677692"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["t5_model.load_state_dict(torch.load(checkpoint_path))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueVmshqvrXd_","executionInfo":{"status":"ok","timestamp":1718576129522,"user_tz":-330,"elapsed":806,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"f963af0b-7718-4515-e13a-fb97559bfd1d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["t5_model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W-h9NzKxrZJK","executionInfo":{"status":"ok","timestamp":1718576132256,"user_tz":-330,"elapsed":3,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"74f4a274-84b5-40da-f2dc-238ff94e3bf0","collapsed":true},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 512)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 8)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-5): 5 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 8)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-5): 5 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["### Retrain"],"metadata":{"id":"GDd8bBiKsb30"}},{"cell_type":"code","source":["#train again\n","trainer = Trainer(\n","  model=t5_model,\n","  args=training_args,\n","  train_dataset=train_dataset,\n","  eval_dataset=val_dataset,\n","  data_collator=data_collator\n",")"],"metadata":{"id":"7S2N5LKpsc-8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#resume from checkpoint\n","trainer.train(resume_from_checkpoint=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":656},"id":"ISDRkqNMtTal","executionInfo":{"status":"ok","timestamp":1718576108731,"user_tz":-330,"elapsed":6583482,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"f0e4e786-cbf5-4e33-bce8-92f02105d56b","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n","/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py:646: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n","  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='14150' max='14150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [14150/14150 1:49:41, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.179500</td>\n","      <td>0.135771</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.172800</td>\n","      <td>0.132057</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.153800</td>\n","      <td>0.128165</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.160000</td>\n","      <td>0.125457</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.150700</td>\n","      <td>0.122636</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.144800</td>\n","      <td>0.120265</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.149100</td>\n","      <td>0.118214</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.152300</td>\n","      <td>0.116671</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.147500</td>\n","      <td>0.115402</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.163700</td>\n","      <td>0.114268</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.137700</td>\n","      <td>0.113360</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.149800</td>\n","      <td>0.112715</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>0.143700</td>\n","      <td>0.112282</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>0.132400</td>\n","      <td>0.112073</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=14150, training_loss=0.0781043372390127, metrics={'train_runtime': 6583.0359, 'train_samples_per_second': 34.391, 'train_steps_per_second': 2.149, 'total_flos': 3.06413838532608e+16, 'train_loss': 0.0781043372390127, 'epoch': 10.0})"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["def generate_json_from_description(description, model, tokenizer, max_length=512):\n","  \"\"\"method to generate JSON from description\n","  Parameters:\n","  description (str): description\n","  model (T5ForConditionalGeneration): model\n","  tokenizer (T5Tokenizer): tokenizer\n","  max_length (int): maximum length of the generated JSON\n","  Returns:\n","  str: generated JSON\"\"\"\n","  #tokenize input description\n","  input_ids= tokenizer(description, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_length).input_ids.to(device)\n","  #generate JSON output\n","  generated_ids= model.generate(input_ids, max_length=max_length, num_beams=5, early_stopping=True)\n","  #decode generated tokens to JSON string\n","  generated_json= tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","  return generated_json"],"metadata":{"id":"3Isoa_-Sne-l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["description=\"Create a professional button with a state of hover\""],"metadata":{"id":"0A6-FRAfne-l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generated_json= generate_json_from_description(description, t5_model, t5_tokenizer)\n"],"metadata":{"id":"_qPlCS97ne-l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(generated_json)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718576144776,"user_tz":-330,"elapsed":11,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"03e3fcb2-6c05-41b1-dce6-c19ebf31f581","id":"SB1VY4EQne-m"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\"\"variant_properties\": \"color\": \"rgba(255, 255, 255, 1.0)\", \"strokes\": [\"rgba(255, 255, 255, 1.0)\"], \"strokeWeight\": 1.0, \"text\": \"Button\", \"textColor\": \"rgba(255, 255, 255, 1.0)\", \"borderRadius\": 9999.0, \"fontFamily\": \"SF Pro Text\", \"fontWeight\": 400, \"fontSize\": 14.0, \"effects\": [\"type\": \"DROP_SHADOW\", \"color\": \"rgba(5, 145, 255, 0.10000000149011612)\"], \"padding\": 0, \"width\": 44.0, \"height\": 24.0, \"x\": -4749.0, \"y\": -4749.0, \"hasIcon\": true, \"style\": \"Professional\", \"component_name\": \"Button\", \"subtype\": \"Default\", \"variant_details\": \"Size\": [\"Large\"], \"State\": [\"hover\"]\"\n"]}]},{"cell_type":"markdown","source":["## Nested"],"metadata":{"id":"uOF0GmbiIue6"}},{"cell_type":"code","source":["#lists\n","json_data=[]\n","prompts=[]"],"metadata":{"id":"Nxuwg56AJ3ch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load json-only\n","json_only_input= '/content/drive/My Drive/Implementation/Final Thesis/FYP/Data/nested_dataset.jsonl'"],"metadata":{"id":"8RcEhM0-J3co"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# json_only= '/content/drive/My Drive/Implementation/Final Thesis/FYP/Data/nested_dataset_5.jsonl'"],"metadata":{"id":"c4lkoWnDMgoR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["jsons = []"],"metadata":{"id":"cB5yIemqMs9B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with open(json_only_input, 'r', encoding='utf-8') as f:\n","#   for line in f:\n","#     json_data = json.loads(line)\n","\n","#     for _ in range(5):\n","#         jsons.append(json_data)"],"metadata":{"id":"lmgCWZrmJ3co"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(json_only, 'w', encoding='utf-8') as f:\n","  for data in jsons:\n","    f.write(json.dumps(data) + '\\n')"],"metadata":{"id":"TxeF72OiMVfB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load prompt only\n","prompt_only='/content/drive/My Drive/Implementation/Final Thesis//FYP/Data/t5_descriptions.txt'"],"metadata":{"id":"XWfwyv_kJ3co"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(prompt_only, 'r', encoding='utf-8') as f:\n","  prompts=[line.strip() for line in f]"],"metadata":{"id":"HDpYWzoPJ3co"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Number of prompts: {len(prompts)}\")\n","print(f\"Number of JSON entries: {len(jsons)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718710863165,"user_tz":-330,"elapsed":8,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"87c82920-6517-4469-b01a-c82ea4c370fe","id":"O_irQX4GJ3co"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of prompts: 28240\n","Number of JSON entries: 28240\n"]}]},{"cell_type":"code","source":["if len(prompts)!= len(jsons):\n","    raise ValueError(\"The number of prompts and JSON entries must be the same\")"],"metadata":{"id":"adfcJ9JXLvi7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class UIDataset(Dataset):\n","  \"\"\" class for loading paired dataset \"\"\"\n","  def __init__(self, prompts, json_data):\n","    \"\"\" method to initialize the class\n","    Parameters:\n","    prompts (list): list of prompts\n","    json_data (list): list of JSON data\n","    \"\"\"\n","    #initialise prompts\n","    self.prompts = prompts\n","    #initialise json data\n","    self.json_data = json_data\n","    #loading bert tokenizer\n","    self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","    self.t5_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n","    #bert model\n","    self.bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n","\n","  def __len__(self):\n","    \"\"\" method to return the length of the dataset \"\"\"\n","    return len(self.prompts)\n","\n","  def __getitem__(self, idx):\n","    \"\"\" method to return the item at the given index\n","    Parameters:\n","    idx (int): index of the item\n","    Returns:\n","    dict: dictionary containing the input_ids, attention_mask, labels, and bert_embeddings\n","    \"\"\"\n","    #indices of prompt and json\n","    prompt = self.prompts[idx]\n","    json_entry = json.dumps(self.json_data[idx])\n","\n","    #bert used to convert prompts to tokens\n","    inputs = self.bert_tokenizer(prompt, return_tensors='pt', padding='max_length', truncation=True, max_length=512).to(device)\n","     #bert embeddings generated without gradient\n","    with torch.no_grad():\n","        outputs = self.bert_model(**inputs)\n","    #average last hidden states from bert to get a single embedding vector for the prompt\n","    bert_embeddings = outputs.last_hidden_state.mean(dim=1).squeeze()\n","\n","    # check for NaN in embeddings\n","    if torch.isnan(bert_embeddings).any():\n","      print(f\"NaN detected in BERT embeddings at index {idx}\")\n","\n","     #t5 tokenizer to conver prompt to tokens\n","    t5_inputs = self.t5_tokenizer(prompt, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n","    #t5 tokenizer to convert json to tokens\n","    targets = self.t5_tokenizer(json_entry, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n","\n","    return {\n","      'input_ids': t5_inputs['input_ids'].squeeze(),\n","      'attention_mask': t5_inputs['attention_mask'].squeeze(),\n","      'labels': targets['input_ids'].squeeze(),\n","      'bert_embeddings': bert_embeddings\n","    }"],"metadata":{"id":"rZCJcMSoIwdh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the dataset\n","dataset= UIDataset(prompts, jsons)\n","total_size= len(dataset)\n","train_size =int(0.8 * total_size)\n","val_size= int(0.1 * total_size)\n","test_size = total_size - train_size - val_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-8TqjRFJm6t","executionInfo":{"status":"ok","timestamp":1718711482758,"user_tz":-330,"elapsed":798,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"384a1e97-9265-401a-9c79-88a057b162dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KSSip2cQJsQx"},"outputs":[],"source":["train_dataset, val_dataset, test_dataset= random_split(dataset, [train_size, val_size, test_size])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cr4jZF6gJsQy"},"outputs":[],"source":["#dataloaders\n","train_loader= DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_loader= DataLoader(val_dataset, batch_size=4)\n","test_loader= DataLoader(test_dataset, batch_size=4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Gll5boHJsQy"},"outputs":[],"source":["#tokenizers and models bert\n","bert_tokenizer= BertTokenizer.from_pretrained('bert-base-uncased')\n","bert_model= BertModel.from_pretrained('bert-base-uncased')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1387,"status":"ok","timestamp":1718711484926,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"},"user_tz":-330},"outputId":"d3ef773f-8017-4034-b633-9644e6630103","collapsed":true,"id":"nTBguP5uJsQy"},"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 512)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 8)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-5): 5 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 8)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-5): 5 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":62}],"source":["#tokenizers and models t5\n","t5_tokenizer= T5Tokenizer.from_pretrained('t5-small')\n","t5_model= T5ForConditionalGeneration.from_pretrained('t5-small')\n","\n","#move to device\n","device= 'cuda' if torch.cuda.is_available() else 'cpu'\n","bert_model.to(device)\n","t5_model.to(device)"]},{"cell_type":"code","source":["# Training arguments\n","training_args= TrainingArguments(\n","  output_dir='/content/drive/My Drive/Implementation/Final Thesis/FYP/JSON generation/T5 CROSS NESTED',\n","  num_train_epochs=5,\n","  #training batch size\n","  per_device_train_batch_size=16,\n","  #evaluation batch size\n","  per_device_eval_batch_size=16,\n","  save_steps=500,\n","  save_total_limit=2,\n","  logging_steps=10,\n","  eval_steps=500,\n","  evaluation_strategy=\"steps\",\n","  prediction_loss_only=True,\n","  load_best_model_at_end=True,\n","  fp16=torch.cuda.is_available(),\n","  #not push to HF\n","  push_to_hub=False\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-47pNnZbJo_k","executionInfo":{"status":"ok","timestamp":1718711484926,"user_tz":-330,"elapsed":7,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"caa529a0-1679-4dcb-ab46-5180ebc62246"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I0ZbEPdeKLVY"},"outputs":[],"source":["#datacollator for seq2seq\n","data_collator = DataCollatorForSeq2Seq(tokenizer=t5_tokenizer, model=t5_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_vZ8SSqrKLWE"},"outputs":[],"source":["class T5WithCrossAttention(T5ForConditionalGeneration):\n","  \"\"\" class for T5 model with cross attention \"\"\"\n","  def __init__(self, config):\n","    \"\"\" method to initialize the class\n","    Parameters:\n","    config (dict): configuration of the model\n","    \"\"\"\n","    super().__init__(config)\n","    #initialise multi head attention layer for cross attention\n","    self.cross_attention = torch.nn.MultiheadAttention(embed_dim=config.d_model, num_heads=8)\n","    #initialise linear layer to put out bert embeddings to t5 hidden state dimension\n","    self.bert_proj = torch.nn.Linear(bert_model.config.hidden_size, config.d_model)\n","\n","  def forward(self, input_ids, attention_mask=None, decoder_input_ids=None, labels=None, bert_embeddings=None):\n","    \"\"\" method to forward the input\n","    Parameters:\n","    input_ids (tensor): input tokens\n","    attention_mask (tensor): attention mask\n","    decoder_input_ids (tensor): decoder input tokens\n","    labels (tensor): labels\n","    bert_embeddings (tensor): bert embeddings\n","    Returns:\n","    tuple: loss and logits\n","    \"\"\"\n","    #pass inputs through t5 encoder\n","    outputs= self.encoder(input_ids=input_ids,attention_mask=attention_mask,)\n","    hidden_states= outputs[0]\n","\n","    #bert embeddings to match the T5 hidden state dimension\n","    bert_embeddings = self.bert_proj(bert_embeddings).unsqueeze(1).expand(-1, hidden_states.size(1), -1)\n","\n","    #putting cross-attention between T5 embeddings and BERT embeddings\n","    hidden_states, _ = self.cross_attention(hidden_states, bert_embeddings, bert_embeddings)\n","\n","    #pass inputs through t5 decoder\n","    decoder_outputs= self.decoder(input_ids=decoder_input_ids,encoder_hidden_states=hidden_states,encoder_attention_mask=attention_mask,)\n","\n","    sequence_output = decoder_outputs[0]\n","    lm_logits = self.lm_head(sequence_output)\n","\n","    loss= None\n","    if labels is not None:\n","      loss_fct= torch.nn.CrossEntropyLoss(ignore_index=-100)\n","      #flatten logits and labels for loss computation\n","      lm_logits = lm_logits.view(-1, lm_logits.size(-1))\n","      #labels\n","      labels= labels.view(-1)\n","      if lm_logits.size(0)== labels.size(0):\n","        loss = loss_fct(lm_logits, labels)\n","      else:\n","        print(f\"Shape mismatch between logits and labels: {lm_logits.size()} vs {labels.size()}\")\n","\n","    return loss, lm_logits\n"]},{"cell_type":"code","source":["#Trainer instance\n","trainer = Trainer(\n","  model=t5_model,\n","  args=training_args,\n","  train_dataset=train_dataset,\n","  eval_dataset=val_dataset,\n","  data_collator=data_collator\n",")"],"metadata":{"id":"anriynLMKLtC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":639},"id":"xDOUeGGWKOCd","executionInfo":{"status":"ok","timestamp":1718718065851,"user_tz":-330,"elapsed":6577655,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"9956aafb-e219-411c-fbb8-e0b834c84cb3","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py:646: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n","  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='7060' max='7060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7060/7060 1:49:35, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.804200</td>\n","      <td>0.617622</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.581100</td>\n","      <td>0.468396</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.501400</td>\n","      <td>0.391192</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.439100</td>\n","      <td>0.341854</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.402200</td>\n","      <td>0.306227</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.386600</td>\n","      <td>0.278159</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.363200</td>\n","      <td>0.256101</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.350200</td>\n","      <td>0.240203</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.320300</td>\n","      <td>0.227243</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.308500</td>\n","      <td>0.216909</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.271200</td>\n","      <td>0.209609</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.278700</td>\n","      <td>0.204458</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.284400</td>\n","      <td>0.201706</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.301000</td>\n","      <td>0.200400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=7060, training_loss=0.46850257328481915, metrics={'train_runtime': 6577.9211, 'train_samples_per_second': 17.173, 'train_steps_per_second': 1.073, 'total_flos': 1.528820989427712e+16, 'train_loss': 0.46850257328481915, 'epoch': 5.0})"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["#path\n","model_save_path= '/content/drive/My Drive/Implementation/Final Thesis/FYP/JSON generation/T5 CROSS NESTED'"],"metadata":{"id":"tQyzJV1mKTJV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#save\n","t5_model.save_pretrained(model_save_path)"],"metadata":{"id":"nBYxUsQsWnC2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t5_tokenizer.save_pretrained(model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718718131474,"user_tz":-330,"elapsed":1302,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"e8c8b2c2-19c4-4ef7-99e7-2c82a594f050","id":"6fQnih8FWnC3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/drive/My Drive/Implementation/Final Thesis/FYP/JSON generation/T5 CROSS NESTED/tokenizer_config.json',\n"," '/content/drive/My Drive/Implementation/Final Thesis/FYP/JSON generation/T5 CROSS NESTED/special_tokens_map.json',\n"," '/content/drive/My Drive/Implementation/Final Thesis/FYP/JSON generation/T5 CROSS NESTED/spiece.model',\n"," '/content/drive/My Drive/Implementation/Final Thesis/FYP/JSON generation/T5 CROSS NESTED/added_tokens.json')"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["def load_model_and_tokenizer(model_path):\n","  \"\"\" method to load the model and tokenizer\n","  Parameters:\n","  model_path (str): path to the model\n","  Returns:\n","  tuple: model and tokenizer\n","  \"\"\"\n","  model = T5ForConditionalGeneration.from_pretrained(model_path)\n","  tokenizer = T5Tokenizer.from_pretrained(model_path)\n","  return model, tokenizer"],"metadata":{"id":"E10xDcmbWnC3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model, tokenizer = load_model_and_tokenizer(model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718718140948,"user_tz":-330,"elapsed":958,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"bdbb726a-5967-4b11-8952-d6e5028dcf8e","id":"qxM-avouWnC3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["def generate_json(prompt, model, tokenizer, max_length=1024):\n","  \"\"\"method to generate json from prompt\n","  Parameters:\n","  prompt (str): prompt to generate json\n","  model (T5ForConditionalGeneration): model to generate json\n","  tokenizer (T5Tokenizer): tokenizer to generate json\n","  max_length (int): maximum length of the generated json\n","  Returns:\n","  str: generated json\n","  \"\"\"\n","  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","  model.to(device)\n","  #tokenize input description\n","  inputs= tokenizer(prompt, return_tensors='pt', padding='max_length', truncation=True, max_length=max_length).to(device)\n","   #generate JSON output\n","  outputs= model.generate(inputs['input_ids'], max_length=max_length,num_beams=5,early_stopping=True,temperature=0)\n","  #decode generated tokens to JSON string\n","  generated_json_str= tokenizer.decode(outputs[0], skip_special_tokens=True)\n","  return generated_json_str"],"metadata":{"id":"g54STuhrZpjw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["description=\"Create a trendy icon-button with a state of hover\""],"metadata":{"id":"WyCoRo8vkrNk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generated_json= generate_json(description, model, tokenizer)\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1718718154986,"user_tz":-330,"elapsed":4297,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"74e55bea-7aa2-4a5b-88a9-40b6c245cb90","id":"VeiMRcA8krNk"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["print(generated_json)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718718157383,"user_tz":-330,"elapsed":2,"user":{"displayName":"K.Ishani","userId":"03791568905300336534"}},"outputId":"97c045e4-8996-4500-a014-fd5e0dca19d7","id":"KF0c7ZWQkrNk"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\"variant_properties\": \"style\": \"Trendy\", \"component_name\": \"icon-button\", \"subtype\": \"Default\", \"variant_details\": \"State\": [\"Hover\"], \"name\": \"State=Hover\", \"type\": \"COMPONENT\", \"children\": [\"name\": \"Content\", \"type\": \"FRAME\", \"width\": 32.0, \"height\": 32.0, \"fills\": [], \"strokes\": [], \"effects\": [], \"borderRadius\": 0, \"strokeWeight\": 1.0, \"children\": [\"name\": \"Icon / SearchOutlined\", \"type\": \"INSTANCE\", \"children\": [\"name\": \"Vector\", \"type\": \"VECTOR\", \"iconWidth\": 12.500054359436035, \"iconHeight\": 12.500054359436035, \"iconColor\": \"r\": 1.0, \"g\": 1.0, \"b\": 1.0, \"a\": 1.0], \"name\": \"Button\", \"type\": \"TEXT\", \"fontFamily\": \"SF Pro Text\", \"fontWeight\": 400, \"fontSize\": 14.0, \"characters\": \"Button\", \"textColor\": \"r\": 1.0, \"g\": 1.0, \"b\": 1.0, \"a\": 1.0]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"EQe8f6P6lczD"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"authorship_tag":"ABX9TyNQeJyj1gzI4Y28693p3E6A"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6c16dfba37ab4a07837e6761671b162c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbec4268cf774f6bb205015b3c8cb87c","IPY_MODEL_0e8519583e8c4583ac5bc4ed7475b8cd","IPY_MODEL_083cd1a8da9b4093ae23b0d233d08dc6"],"layout":"IPY_MODEL_3d94a12c468a47fbbf05e3a566420b66"}},"bbec4268cf774f6bb205015b3c8cb87c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_110de3f44b174cb786e1f5fb7f631839","placeholder":"‚Äã","style":"IPY_MODEL_36fbe96f8c804b39a73f32ba7722b9de","value":"tokenizer_config.json:‚Äá100%"}},"0e8519583e8c4583ac5bc4ed7475b8cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dae370e508548bb927aaed7a5e7fad8","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b0f4e2283a841acab1d07f3584a3211","value":48}},"083cd1a8da9b4093ae23b0d233d08dc6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e918e02ff4d4830a4a4c5f404e50112","placeholder":"‚Äã","style":"IPY_MODEL_dc6ac7c852c14b708e601504697fbbd4","value":"‚Äá48.0/48.0‚Äá[00:00&lt;00:00,‚Äá3.86kB/s]"}},"3d94a12c468a47fbbf05e3a566420b66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"110de3f44b174cb786e1f5fb7f631839":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36fbe96f8c804b39a73f32ba7722b9de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5dae370e508548bb927aaed7a5e7fad8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b0f4e2283a841acab1d07f3584a3211":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e918e02ff4d4830a4a4c5f404e50112":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc6ac7c852c14b708e601504697fbbd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65c57afb6f5043a2add3c6af7af07a95":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4c0a5ed3bc244339e15c827a96ffefe","IPY_MODEL_88b9a70da82e4ad9a7ce9d1035fd92ad","IPY_MODEL_2c92842997094c70893db8b967871549"],"layout":"IPY_MODEL_8867c12d6b034897b16f91402244f333"}},"d4c0a5ed3bc244339e15c827a96ffefe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_542b9f4fbe3849dc92795a4574864132","placeholder":"‚Äã","style":"IPY_MODEL_df1882ccd80544b5bec952e250451ea5","value":"vocab.txt:‚Äá100%"}},"88b9a70da82e4ad9a7ce9d1035fd92ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_779e63e71cc04803969593ca3ffeaf4c","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bcad1951727455ea68ad23d419128dc","value":231508}},"2c92842997094c70893db8b967871549":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b446c945cf764f2cac1b2f8b6d61521e","placeholder":"‚Äã","style":"IPY_MODEL_d9fcd38a2af44b28a3d8afd67f5a140a","value":"‚Äá232k/232k‚Äá[00:00&lt;00:00,‚Äá10.6MB/s]"}},"8867c12d6b034897b16f91402244f333":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"542b9f4fbe3849dc92795a4574864132":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df1882ccd80544b5bec952e250451ea5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"779e63e71cc04803969593ca3ffeaf4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bcad1951727455ea68ad23d419128dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b446c945cf764f2cac1b2f8b6d61521e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9fcd38a2af44b28a3d8afd67f5a140a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"245f2e295b1a4d7eba2742bbdc4db771":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b8475befd5342a2a2cae98bcb5f3eea","IPY_MODEL_c7b1bb35879a4361b102967b4631eee4","IPY_MODEL_c9c7970114b14a0fb657cec8f9585085"],"layout":"IPY_MODEL_7b5067e099194fc7a3dc64d5f027f485"}},"4b8475befd5342a2a2cae98bcb5f3eea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17a5a49d385f43e0b205a247b4f731c0","placeholder":"‚Äã","style":"IPY_MODEL_4a0de5820ee64301b950044977c3bf95","value":"tokenizer.json:‚Äá100%"}},"c7b1bb35879a4361b102967b4631eee4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_53079e505fa943c88c0ed6ada4c43e8d","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb9ec75c2ce74629818463a3e0b76369","value":466062}},"c9c7970114b14a0fb657cec8f9585085":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b742819c36c349e8a356afd8279bed8f","placeholder":"‚Äã","style":"IPY_MODEL_51e20ec44b6740289ce77c96bf0ec927","value":"‚Äá466k/466k‚Äá[00:00&lt;00:00,‚Äá26.8MB/s]"}},"7b5067e099194fc7a3dc64d5f027f485":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17a5a49d385f43e0b205a247b4f731c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a0de5820ee64301b950044977c3bf95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53079e505fa943c88c0ed6ada4c43e8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb9ec75c2ce74629818463a3e0b76369":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b742819c36c349e8a356afd8279bed8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51e20ec44b6740289ce77c96bf0ec927":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1bbc741e80a4e4a958beee0c25fd2f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab581ce3bfb44fd6a2ab268f0e0ef0c7","IPY_MODEL_5c1d2452c08c4573803db56d4e491002","IPY_MODEL_073fb82d5d014e0cb75386179c70e3c4"],"layout":"IPY_MODEL_15823ae2f74843f096a0afa30927617e"}},"ab581ce3bfb44fd6a2ab268f0e0ef0c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b08576f8c0b4f41a6765f3ce018c4a5","placeholder":"‚Äã","style":"IPY_MODEL_8aafc6d2583a42db9a29dd9bbeb44c53","value":"config.json:‚Äá100%"}},"5c1d2452c08c4573803db56d4e491002":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae70960250b44f59ad373d1a986f2c76","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c24bbd022b174601872a0484c0fcb928","value":570}},"073fb82d5d014e0cb75386179c70e3c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a98cd2ffff1f4250bcdf29211fd7dee2","placeholder":"‚Äã","style":"IPY_MODEL_f83178a6d7924071b0985052d513c789","value":"‚Äá570/570‚Äá[00:00&lt;00:00,‚Äá47.7kB/s]"}},"15823ae2f74843f096a0afa30927617e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b08576f8c0b4f41a6765f3ce018c4a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8aafc6d2583a42db9a29dd9bbeb44c53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae70960250b44f59ad373d1a986f2c76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c24bbd022b174601872a0484c0fcb928":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a98cd2ffff1f4250bcdf29211fd7dee2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f83178a6d7924071b0985052d513c789":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0a7ff38fa0c4ce0a5f40e7eae3b88e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7dca6a89e1284ecc88b79df35a66160b","IPY_MODEL_fffe9e61321c412f9c7b99de06076b98","IPY_MODEL_5b42baf65f7c44a189e1ceee8563819b"],"layout":"IPY_MODEL_72c41f0bd39447fcb398737b149285fc"}},"7dca6a89e1284ecc88b79df35a66160b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fe0b66e42df4e08ac315a2c5bff573e","placeholder":"‚Äã","style":"IPY_MODEL_41022d6c673e4ca3bf69dfb407d59b78","value":"tokenizer_config.json:‚Äá100%"}},"fffe9e61321c412f9c7b99de06076b98":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b73bb014c99c49b498515896ecc5ba17","max":2324,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81d2e72ebbdf4e06b8c2b3c6b591e1ac","value":2324}},"5b42baf65f7c44a189e1ceee8563819b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35a975c242b0493c96dd9a0a240986a2","placeholder":"‚Äã","style":"IPY_MODEL_9d56eb7db23f43688801d5a7ec9fe4c2","value":"‚Äá2.32k/2.32k‚Äá[00:00&lt;00:00,‚Äá211kB/s]"}},"72c41f0bd39447fcb398737b149285fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fe0b66e42df4e08ac315a2c5bff573e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41022d6c673e4ca3bf69dfb407d59b78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b73bb014c99c49b498515896ecc5ba17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81d2e72ebbdf4e06b8c2b3c6b591e1ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"35a975c242b0493c96dd9a0a240986a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d56eb7db23f43688801d5a7ec9fe4c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"016f0264dca1455bb0bb147a1026fbc6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02d5551b6946412d854316917a9aa289","IPY_MODEL_c6cdd32e69d04b15932d77f880cea07d","IPY_MODEL_fe5a19d6ea694e249c053e8e8952c636"],"layout":"IPY_MODEL_8e733cf3513542eea44b856a7c00dccc"}},"02d5551b6946412d854316917a9aa289":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b6c70db7c614597af4d28edf2d1fb13","placeholder":"‚Äã","style":"IPY_MODEL_1bf2c0a720f04b6aa85442bc28676ce3","value":"spiece.model:‚Äá100%"}},"c6cdd32e69d04b15932d77f880cea07d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0a048b7a9754d9cb9ed333050a601dc","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7aad9107ad2646b5a6803d672e01aaad","value":791656}},"fe5a19d6ea694e249c053e8e8952c636":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27ce6c258c1d485d896a135fc7df8275","placeholder":"‚Äã","style":"IPY_MODEL_009b8f4e042a4a1592ba6a0c7076def8","value":"‚Äá792k/792k‚Äá[00:00&lt;00:00,‚Äá37.5MB/s]"}},"8e733cf3513542eea44b856a7c00dccc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b6c70db7c614597af4d28edf2d1fb13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bf2c0a720f04b6aa85442bc28676ce3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0a048b7a9754d9cb9ed333050a601dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7aad9107ad2646b5a6803d672e01aaad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27ce6c258c1d485d896a135fc7df8275":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"009b8f4e042a4a1592ba6a0c7076def8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d47348a8e5b845d698132111767194f4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa0f9e83f7ff4360b9d3f15261f7e0ea","IPY_MODEL_53f6d196bd42443e9f56352065313809","IPY_MODEL_2ae616b53dd241d8bfc46ccb5208a4b1"],"layout":"IPY_MODEL_3d9bbdd495194ba18b4417be8ac86d22"}},"fa0f9e83f7ff4360b9d3f15261f7e0ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21c8c6a8632b4ac38168609c3ba20863","placeholder":"‚Äã","style":"IPY_MODEL_7b157bf3745b4055a674350ea4b62384","value":"tokenizer.json:‚Äá100%"}},"53f6d196bd42443e9f56352065313809":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f24594b8df964a00b8108097f950b19c","max":1389353,"min":0,"orientation":"horizontal","style":"IPY_MODEL_edca598b10e74a30aa753c3f2d6e3848","value":1389353}},"2ae616b53dd241d8bfc46ccb5208a4b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b065ee80eef144dfbee36ecf6ba56c94","placeholder":"‚Äã","style":"IPY_MODEL_40a104105bc14d219193df623fc90465","value":"‚Äá1.39M/1.39M‚Äá[00:00&lt;00:00,‚Äá2.88MB/s]"}},"3d9bbdd495194ba18b4417be8ac86d22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21c8c6a8632b4ac38168609c3ba20863":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b157bf3745b4055a674350ea4b62384":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f24594b8df964a00b8108097f950b19c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edca598b10e74a30aa753c3f2d6e3848":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b065ee80eef144dfbee36ecf6ba56c94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40a104105bc14d219193df623fc90465":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f22d02369534694b4f276c2b6fbcabe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a8800915bf7847c1b9bd55430b1121a5","IPY_MODEL_23b43fbe94dd4ddbb23ce7f2aedfb98f","IPY_MODEL_7c5e4bb5b9a1436d8153b492713e0b52"],"layout":"IPY_MODEL_89f97101efb04978a58da5e291933f6b"}},"a8800915bf7847c1b9bd55430b1121a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1955ab2511241ce9a7f21f24db54be8","placeholder":"‚Äã","style":"IPY_MODEL_e6911b05e304460dbe9d0879051b8247","value":"model.safetensors:‚Äá100%"}},"23b43fbe94dd4ddbb23ce7f2aedfb98f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31293e1ed404428c9f5c4a936c7e38ec","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_97a2eb9f0c0d4393b3a4d56d8000570e","value":440449768}},"7c5e4bb5b9a1436d8153b492713e0b52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca2f3fc8b98347e4b3b8d5ac8d2b5a70","placeholder":"‚Äã","style":"IPY_MODEL_f34e1bd2d2d64b4fbad97cf98bf733fb","value":"‚Äá440M/440M‚Äá[00:01&lt;00:00,‚Äá494MB/s]"}},"89f97101efb04978a58da5e291933f6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1955ab2511241ce9a7f21f24db54be8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6911b05e304460dbe9d0879051b8247":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31293e1ed404428c9f5c4a936c7e38ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97a2eb9f0c0d4393b3a4d56d8000570e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca2f3fc8b98347e4b3b8d5ac8d2b5a70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f34e1bd2d2d64b4fbad97cf98bf733fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39ed39a45385449fa405148cac55a0b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f38285c1407b4e0ea6a2b181626e4e1c","IPY_MODEL_8ab0949b42134f258d9c8fba04dd2da4","IPY_MODEL_18ffa2ff4c7f45b5a877bfdf1e4d9d94"],"layout":"IPY_MODEL_3a426cbe30d94adab6b9a01cc7b2b932"}},"f38285c1407b4e0ea6a2b181626e4e1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b9323aa944e4ebd808cfd4b629f4d4a","placeholder":"‚Äã","style":"IPY_MODEL_1983a7898198474fb027ac52d9b877ba","value":"config.json:‚Äá100%"}},"8ab0949b42134f258d9c8fba04dd2da4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_550ef2a0008349919dca50d3f3726338","max":1206,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e1fe2626f124ed0972686477c34fdff","value":1206}},"18ffa2ff4c7f45b5a877bfdf1e4d9d94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9dc5bdd1aec46d2b15af1714ca15e40","placeholder":"‚Äã","style":"IPY_MODEL_b756f98d602d4957a5818179973f8a32","value":"‚Äá1.21k/1.21k‚Äá[00:00&lt;00:00,‚Äá109kB/s]"}},"3a426cbe30d94adab6b9a01cc7b2b932":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b9323aa944e4ebd808cfd4b629f4d4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1983a7898198474fb027ac52d9b877ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"550ef2a0008349919dca50d3f3726338":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e1fe2626f124ed0972686477c34fdff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9dc5bdd1aec46d2b15af1714ca15e40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b756f98d602d4957a5818179973f8a32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aed87e36495940e5acc866fba5cdb066":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ef71b336ccfe4959a6261b0da0017b28","IPY_MODEL_f14786f0c84948de9d3054efb0928f50","IPY_MODEL_db045e0d09f146618aa9ac27455adb35"],"layout":"IPY_MODEL_8199be36cb3e43e1b9f92e8e4a67890a"}},"ef71b336ccfe4959a6261b0da0017b28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f864738a7884333828934549ef04f55","placeholder":"‚Äã","style":"IPY_MODEL_bde57b79362b45999bd1e29e857fb689","value":"model.safetensors:‚Äá100%"}},"f14786f0c84948de9d3054efb0928f50":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebf7a9b6506e4ff38cb47e65c45ade26","max":242043056,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73f5513418734247855aea71596127af","value":242043056}},"db045e0d09f146618aa9ac27455adb35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1b6eac649574cdfbedfbb41a6c65601","placeholder":"‚Äã","style":"IPY_MODEL_6316c4be7844463ca7c80788f1a09a96","value":"‚Äá242M/242M‚Äá[00:00&lt;00:00,‚Äá409MB/s]"}},"8199be36cb3e43e1b9f92e8e4a67890a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f864738a7884333828934549ef04f55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bde57b79362b45999bd1e29e857fb689":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebf7a9b6506e4ff38cb47e65c45ade26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73f5513418734247855aea71596127af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a1b6eac649574cdfbedfbb41a6c65601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6316c4be7844463ca7c80788f1a09a96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4010ea7775740f69f8e4b54b64361c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f627a42861654d0e84c312ac259fa75d","IPY_MODEL_ca5b1325394f4d69b0c587b683a32c3b","IPY_MODEL_c944ff2044904d9b8fd2066bce303dab"],"layout":"IPY_MODEL_a39ca21b1b564204bfa1d20d34a4783e"}},"f627a42861654d0e84c312ac259fa75d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d31b9e61e754f86852c06d2e217e694","placeholder":"‚Äã","style":"IPY_MODEL_8c0298cc48b94c58bf6d1197e825f620","value":"generation_config.json:‚Äá100%"}},"ca5b1325394f4d69b0c587b683a32c3b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_883aa355b39f43c1878cc20be46c905e","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4daf686d65b3463eb4edc708080514a3","value":147}},"c944ff2044904d9b8fd2066bce303dab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc0f22c815664a64b84ae607179972dd","placeholder":"‚Äã","style":"IPY_MODEL_aee2d2f8b7224b1da453880f30ec30f8","value":"‚Äá147/147‚Äá[00:00&lt;00:00,‚Äá7.74kB/s]"}},"a39ca21b1b564204bfa1d20d34a4783e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d31b9e61e754f86852c06d2e217e694":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c0298cc48b94c58bf6d1197e825f620":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"883aa355b39f43c1878cc20be46c905e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4daf686d65b3463eb4edc708080514a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc0f22c815664a64b84ae607179972dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aee2d2f8b7224b1da453880f30ec30f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}